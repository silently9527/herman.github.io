import{_ as o}from"./chunks/ArticleMetadata.XuUbZ1GH.js";import{_ as l,D as n,o as r,c,I as p,w as d,k as s,a as m,R as u,b as g,e as f}from"./chunks/framework.PNf1_BA9.js";import"./chunks/md5.c4H53MUT.js";const N=JSON.parse('{"title":"一致性Hash算法Java版实现","description":"","frontmatter":{"title":"一致性Hash算法Java版实现","author":"Herman","date":"2021/08/14 13:58","categories":["算法"],"tags":["算法","一致性hash"]},"headers":[],"relativePath":"article/pamphlet/algorithms/卧学算法/01-一致性Hash算法Java版实现.md","filePath":"article/pamphlet/algorithms/卧学算法/01-一致性Hash算法Java版实现.md","lastUpdated":1723429417000}'),_={name:"article/pamphlet/algorithms/卧学算法/01-一致性Hash算法Java版实现.md"},b=s("h1",{id:"一致性hash算法java版实现",tabindex:"-1"},[m("一致性Hash算法Java版实现 "),s("a",{class:"header-anchor",href:"#一致性hash算法java版实现","aria-label":'Permalink to "一致性Hash算法Java版实现"'},"​")],-1),k=u('<h2 id="前言" tabindex="-1">前言 <a class="header-anchor" href="#前言" aria-label="Permalink to &quot;前言&quot;">​</a></h2><p>在之前写了两篇关于缓存的文章<a href="https://www.toutiao.com/i6913902641764565507/" target="_blank" rel="noreferrer">《万字长文聊缓存（上）- http缓存》</a><a href="https://www.toutiao.com/i6913903843189441038/" target="_blank" rel="noreferrer">《万字长文聊缓存（下）- 应用级缓存》</a>，谈到缓存不说一下一致性Hash算法那就是在耍流氓。</p><h2 id="分布式缓存集群的访问模型" tabindex="-1">分布式缓存集群的访问模型 <a class="header-anchor" href="#分布式缓存集群的访问模型" aria-label="Permalink to &quot;分布式缓存集群的访问模型&quot;">​</a></h2><p>现在通常使用Redis来做分布式缓存，下面我们就以Redis为例：</p><p><img src="https://raw.githubusercontent.com/silently9527/images/main/1473020696-5ff71a4e81b9c_articlex" alt=""></p><p>假如当前我们系统的业务发展很快，需要缓存的数据很多，所以我们做了一个由三组主从复制的redis组成的高可用的redis集群，如何将请求路由的不同的redis集群上，这是我们需要考虑的，常用的路由算法：</p><p><strong>随机算法</strong>：每次将请求随机的发送到其中一组Redis集群中，这种算法的好处是请求会被均匀的分发到每组Redis集群上；缺点也很明显，由于随机分发请求，为了提高缓存的命中率，所以同一份数据需要在每组集群中都存在，这样就会造成了数据的冗余，浪费了存储空间</p><p><strong>Hash算法</strong>：针对随机算法的问题，我们可以考虑Hash算法，举例： 现在有三组redis集群，我们可以对每次缓存key的hash值取模，公式：<code>index=hash(key) % 3</code>，index的值就对应着3组集群，这样就可以保证同一个请求每次都被分发到同一个redis集群上，无需对数据做冗余，完美的解决了刚才随机算法的缺点；</p><p><img src="https://raw.githubusercontent.com/silently9527/images/main/2921673907-5ff7216407514_articlex" alt=""></p><p>但是hash算法也有缺点：对于容错性和伸缩性支持很差，举例：当我们三组redis集群中其中一组节点宕机了，那么此时的redis集群中可用的数量变成了2，公式变成了<code>index=hash(key) % 2</code>， 所有数据缓存的节点位置就发生了变化，造成缓存的命中率直线下降；</p><p>同理，当我们需要扩展一组新的redis机器，计算的公式<code>index=hash(key) % 4</code>，大量的key会被重新定位到其他服务器，也会造成缓存的命中率下降。</p><p>为了解决hash算法容错性和伸缩性的问题，一致性hash算法由此而生~</p><h2 id="一致性哈希算法" tabindex="-1">一致性哈希算法 <a class="header-anchor" href="#一致性哈希算法" aria-label="Permalink to &quot;一致性哈希算法&quot;">​</a></h2><h4 id="具体的算法过程" tabindex="-1">具体的算法过程 <a class="header-anchor" href="#具体的算法过程" aria-label="Permalink to &quot;具体的算法过程&quot;">​</a></h4><ol><li>先构造一个长度为2^32-1的整数环（称为一致性hash环），然后给每组redis集群命名，根据名字的hash值计算出每组集群应该放在什么位置</li></ol><p><img src="https://raw.githubusercontent.com/silently9527/images/main/2200732345-5ff72a3b81035_articlex" alt=""></p><ol start="2"><li>根据缓存数据的key计算出hash值，计算出出来的hash值同样也分布在一致性hash环上; 假如现在有5个数据需要缓存对应的key分别为key1、key2、key3、key4、key5，计算hash值之后的分部如下图</li></ol><p><img src="https://raw.githubusercontent.com/silently9527/images/main/3371805372-5ff72c525593e_articlex" alt=""></p><ol start="3"><li>然后顺着hash环顺时针方向查找reids集群，把数据存放到最近的集群上</li></ol><p><img src="https://raw.githubusercontent.com/silently9527/images/main/888076508-5ff72d221e3d6_articlex" alt=""></p><p>最后所有key4、key5存放在了集群2，key1、key3存放在了集群1，key2存放在了集群3</p><h4 id="容错性" tabindex="-1">容错性 <a class="header-anchor" href="#容错性" aria-label="Permalink to &quot;容错性&quot;">​</a></h4><p>还是继续沿用上面的例子，我们来看下一致性哈希算法的容错性如何呢？假如其中 集群1 跪了，那么影响的数据只有key1和key3，其他数据存放的位置不受影响；当再次缓存key1、key3的时候根据顺时针查找，会把数据存放到集群3上面</p><h4 id="伸缩性" tabindex="-1">伸缩性 <a class="header-anchor" href="#伸缩性" aria-label="Permalink to &quot;伸缩性&quot;">​</a></h4><p>如果我们需要在当前的基础上再添加一组redis集群4，根据名字hash之后的位置在集群1和集群2之间</p><p><img src="https://raw.githubusercontent.com/silently9527/images/main/4185943574-5ff730f79e6b8_articlex" alt=""></p><p>新加redis集群4之后影响的只有key1数据，其他数据不受影响。</p><h4 id="数据倾斜问题" tabindex="-1">数据倾斜问题 <a class="header-anchor" href="#数据倾斜问题" aria-label="Permalink to &quot;数据倾斜问题&quot;">​</a></h4><p>经过容错性、伸缩性的验证证明了一致性哈希算法确实能解决Hash算法的问题，但是现在的算法就是完美的吗？让我们继续来看刚才容错性的例子，加入集群1跪了，那么原来落在集群1上的所有数据会直接落在集群3上面，如果说每组redis集群的配置都是一样的，那么集群3的压力会增大，数据分布不均匀造成数据倾斜问题。</p><p><img src="https://raw.githubusercontent.com/silently9527/images/main/3395061273-5ff734d50b733_articlex" alt=""></p><p>怎么搞呢？</p><p>歪果仁的脑子就是好使，给的解决方案就是加一层虚拟层，假如每组集群都分配了2个虚拟节点</p><table><thead><tr><th>集群</th><th>虚拟节点</th></tr></thead><tbody><tr><td>集群1</td><td>vnode1, vnode2</td></tr><tr><td>集群2</td><td>vnode3, vnode4</td></tr><tr><td>集群3</td><td>vnode5, vnode6</td></tr></tbody></table><p>接下来就是把虚拟节点放入到一致性hash环上，在缓存数据的时候根据顺时针查找虚拟节点，在根据虚拟节点的和实际集群的对应关系把数据存放到redis集群，这样数据就会均匀的分布到各组集群中。</p><p><img src="https://raw.githubusercontent.com/silently9527/images/main/1902317969-5ff7382424a87_articlex" alt=""></p><p>这时候如果有一组redis集群出现了问题，那么这组集群上面的key会相对均匀的分摊到其他集群上。</p><p>从上面的结果来看，只要每组集群对应的虚拟节点越多，那么各个物理集群的数据分布越均匀，当新增加或者减少物理集群影响也会最小，但是如果虚拟节点太多会影响查找的性能，太少数据又会不均匀，那么多少合适呢？根据一些大神的经验给出的建议是 <strong>150</strong> 个虚拟节点。</p><h2 id="一致性hash算法java版实现-1" tabindex="-1">一致性Hash算法Java版实现 <a class="header-anchor" href="#一致性hash算法java版实现-1" aria-label="Permalink to &quot;一致性Hash算法Java版实现&quot;">​</a></h2><p>实现思路：在每次添加物理节点的时候，根据物理节点的名字生成虚拟节点的名字，把虚拟节点的名字求hash值，然后把hash值作为key，物理节点作为value存放到Map中；这里我们选择使用TreeMap，因为需要key是顺序的存储；在计算数据key需要存放到哪个物理节点时，先计算出key的hash值，然后调用TreeMap.tailMap()返回比hash值大的map子集，如果子集为空就需要把TreeMap的第一个元素返回，如果不为空，那么取子集中的第一个元素。</p><blockquote><p>不扯废话，直接上代码，No BB . Show me the code</p></blockquote><h4 id="核心代码" tabindex="-1">核心代码： <a class="header-anchor" href="#核心代码" aria-label="Permalink to &quot;核心代码：&quot;">​</a></h4><p><img src="https://raw.githubusercontent.com/silently9527/images/main/239129110-5ff920a833672_articlex" alt=""></p><p><img src="https://raw.githubusercontent.com/silently9527/images/main/1196969428-5ff92065d14d7_articlex" alt=""></p><h4 id="测试代码" tabindex="-1">测试代码： <a class="header-anchor" href="#测试代码" aria-label="Permalink to &quot;测试代码：&quot;">​</a></h4><p><img src="https://raw.githubusercontent.com/silently9527/images/main/1222387125-5ff9213d44cd3_articlex" alt=""></p><ol><li>测试删除节点node3，对比命中率影响了多少 添加如下代码：</li></ol><p><img src="https://raw.githubusercontent.com/silently9527/images/main/2593358087-5ff921ec7a9bc_articlex" alt=""></p><p>执行结果：</p><p><img src="https://raw.githubusercontent.com/silently9527/images/main/81698353-5ff9222578918_articlex" alt=""></p><ol start="2"><li>测试添加节点node5，对比命中率影响了多少 添加如下代码：</li></ol><p><img src="https://raw.githubusercontent.com/silently9527/images/main/183277056-5ff92275158ec_articlex" alt=""></p><p>执行结果：</p><p><img src="https://raw.githubusercontent.com/silently9527/images/main/481493202-5ff922b157377_articlex" alt=""></p><h2 id="其他使用场景" tabindex="-1">其他使用场景 <a class="header-anchor" href="#其他使用场景" aria-label="Permalink to &quot;其他使用场景&quot;">​</a></h2><p><img src="https://raw.githubusercontent.com/silently9527/images/main/775014904-5ff71811b8eb4_articlex" alt=""></p><p>看上图，在Nginx请求的分发过程中，为了让应用本地的缓存命中率最高，我们希望根据请求的URL或者URL参数将相同的请求转发到同一个应用服务器中，这个时候也可以选择使用一致性hash算法。具体配置可以参考官方文档: <a href="https://www.nginx.com/resources/wiki/modules/consistent_hash/" target="_blank" rel="noreferrer">https://www.nginx.com/resources/wiki/modules/consistent_hash/</a></p><p><img src="https://raw.githubusercontent.com/silently9527/images/main/2066161866-5ff869d074933_articlex" alt=""></p>',57);function y(a,x,w,q,v,P){const i=o,h=n("ClientOnly");return r(),c("div",null,[b,p(h,null,{default:d(()=>{var e,t;return[(((e=a.$frontmatter)==null?void 0:e.aside)??!0)&&(((t=a.$frontmatter)==null?void 0:t.showArticleMetadata)??!0)?(r(),g(i,{key:0,article:a.$frontmatter},null,8,["article"])):f("",!0)]}),_:1}),k])}const R=l(_,[["render",y]]);export{N as __pageData,R as default};
